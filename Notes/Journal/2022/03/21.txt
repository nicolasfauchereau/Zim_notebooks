Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.4
Creation-Date: 2022-03-21T11:06:24+13:00

====== Monday 21 Mar 2022 ======

==== ICU C3S notebooks ====

@ICU 

finalised the 8_map_ICU_Water_Stress_outlook.ipynb notebook 

--------------------

==== S2S AI challenge ====

@RPS @RPSS 

ranked probability skill score 

see in 

[[/home/nicolasf/research/S2S_AI/s2s-ai-challenge-Landry_CRIM_winner/notebooks/scripts.py]] 

**skill_by_year** function for an example of the use of 

**xskillscore.rps** (https://xskillscore.readthedocs.io/en/stable/api/xskillscore.rps.html) 

seems that all one needs is for the observations to be coded as probabilities, so for example for probabilistic forecasts there is probability of 1 for the observed category, 0 elsewehere 

one also calculates the RPS of the climatology

clim_p = xr.DataArray([1/3, 1/3, 1/3], dims='category', coords={'category':['below normal', 'near normal', 'above normal']}).to_dataset(name='tp')

and the RPSS (Ranked Probability Skill Score) is calculated as 

rpss = 1 - (rps_ML.mean('forecast_time') / rps_clim.mean('forecast_time')) 

--------------------

==== ICU forecasts verification ====

@ICU 

with climpred, see 

https://climpred.readthedocs.io/en/stable/metrics.html#ranked-probability-score

for the calculation of the RPS: 


q = [1 / 3, 2 / 3]  # terciles by month
forecast_edges = (
	HindcastEnsemble.get_initialized()
	.groupby("init.month")
	.quantile(q=q, dim=["init", "member"])
	.rename({"quantile": "category_edge"})
)
obs_edges = (
	HindcastEnsemble.get_observations()
	.groupby("time.month")
	.quantile(q=q, dim="time")
	.rename({"quantile": "category_edge"})
)
category_edges = (obs_edges, forecast_edges)
HindcastEnsemble.verify(
	metric="rps",
	comparison="m2o",
	dim=["member", "init"],
	alignment="same_verifs",
	category_edges=category_edges,
)

see in notebooks: 

→ **climpred_RPS.ipynb** 
→ **validate_terciles_probabilistic_hindcasts_MME_RPSS.ipynb** 

















